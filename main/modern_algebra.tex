\section{Preliminary theory - modern algebra}

    Let us first go over some modern algebra \cite{joyce2008}. Modern algebra, or abstract algebra, is the mathematical branch that studies sets and associated operations (algebraic structures) and relations between them.

    \subsection{Relations between sets}
        Modern algebra starts from the notion of a set. A set $S$ is a collection of elements:
        \begin{equation}
            S = \set{s_1, s_2, \dots, s_n} \thinspace .
        \end{equation}
        Some examples of sets are the set of natural numbers $\N$, the set of real numbers $\R$, the set of complex numbers $\C$. We can also have smaller sets, for example
        \begin{equation}
            S = \set{0, 1} \thinspace ,
        \end{equation}
        being the set of the numbers $0$ and $1$. Sets don't necessarily have to contain only numbers. We can, for example, collect all invertible $n \times n$-matrices in a set:
        \begin{equation}
            \GLg(n, \mathbb{R}) = \set{A \in \mathbb{R}^{n \times n} ; \text{$A$ is invertible}} \thinspace ,
        \end{equation}
        in which the symbol $\GLg$ has to do with `general linear', but more on that when we encounter the general linear group. \\

        The previous examples are all concrete (i.e. not abstract) examples of sets. Now say we have a mathematical object, called $E$ (we haven't specified anything about it), we can say that
        \begin{equation}
            G = \set{E}
        \end{equation}
        is also a set, but in a more abstract sense than the previous examples. We can enlarge this set by adding the elements $C_2, \sigma_v$ and $\sigma_v'$, to end up with
        \begin{equation}
            G = \set{E, C_2, \sigma_v, \sigma_v'} \thinspace ,
        \end{equation}
        in which we still haven't specified anything about the nature of its elements, but in mathematics that is perfectly fine. \\

        Naturally, if we have two different sets, we would like to be able to define relations between their elements. This is exactly what a function does. A function (or map, mapping, these are all synonyms) is a relation between two sets $X$ and $Y$:
        \begin{equation} \label{eq:def_function}
            f: X \rightarrow Y: x \mapsto y = f(x) ,
        \end{equation}
        subject to the important condition that every input $x \in X$ is related to exactly one output $y \in Y$. We would read the definition in equation (\ref{eq:def_function}) as follows: $f$ is a function from the set $X$ to the set $Y$, in which every $x \in X$ is related to a $y \in Y$, which we call $f(x)$. \\

        We give special names to the sets $X$ and $Y$, depending on which role they play in the function. The set $X$ is called the domain of the function: it is the set of all inputs for the function. The set $Y$ is then called the function's codomain: it is the set of values that \emph{could} occur as output values for the function. We can then define another set, $Z$, which is called the image of the function: it is the set of \emph{actual} values for the outputs. A visual clarification of the terms can be found in Figure \ref{fig:functions}. \\
        \begin{figure}[H] \centering
            \includegraphics{images/functions}
            \caption{The definition of a function, and a visual clarification of the terms domain, codomain and image. The domain is the set of input values, the codomain is the set of possible output values, and the images is the set of actual output values.}
            \label{fig:functions}
        \end{figure}

        An example of a function could be:
        \begin{equation}
            f: \R \rightarrow \R: x \mapsto f(x) = x^2 + 2
        \end{equation}
        Its domain is $\R$, and its codomain is also $\R$. Here, we can also see the difference between the codomain and the image. The codomain of this function is defined to be $\R$, but its image $[2, +\infty[$. Another example is shown in Figure \ref{fig:function_color}.
        \begin{figure}[H] \centering
            \includegraphics[scale=0.4]{images/function_color}
            \caption{An example of a function that maps an object to its color.}
            \label{fig:function_color}
        \end{figure}
        The reason why this is a function is because every input element of the set $X$, being shapes in a certain color, is related to its color, represented as elements of the set $Y$. In this case, $Y$, the codomain is the set of colors depicted as elements of $Y$, and the range is the set of colors red, green and yellow. \\

        We have seen some examples of functions already, but what are some examples of non-functions? There are actually two requirements to the definition of a function:
        \begin{enumerate}
            \item Every input (element of the domain) has to be related to an output (element of the codomain)
            \item No two outputs (elements of the codomain) may be related to the same input (element of the domain)
        \end{enumerate}
        With these two criteria in mind, it is possible to come up with many examples of relations between two sets that are not functions, for example those shown in Figure \ref{fig:non_functions}.
        \begin{figure}[H] \centering
            \includegraphics{images/non_functions}
            \caption{Two examples of non-functions. The first relation between $X$ and $Y$ is not a function, because not every element of $X$ is related to an element of $Y$. The second figure is not a function because there is an element of $X$ related to two elements of $Y$.}
            \label{fig:non_functions}
        \end{figure}

        An operation is a special kind of function. It is a function
        \begin{equation}
            \omega: X^n \rightarrow X \thinspace ,
        \end{equation}
        which takes $n$ elements from the set $X$ as input, and relates that combination to the set $X$ itself. \\

        We know many operations, for example number addition, which takes two numbers as input and relates that combination to another number. Number multiplication is another example of a binary operation: we take two numbers, whose product is another number. The set $X$ is not confined to be a set of numbers. If we take, for example, set of $n \times n$ matrices, then matrix multiplication is an example of a binary operation. \\

        By now, we have seen some examples of functions. In order to classify functions, we will introduce the terms surjection, injection, and bijection. For a visual overview of the terms, see Figure \ref{fig:sur_in_bi}. \\

        A function is called surjective (or: onto), if every element of its codomain is mapped to. \emph{Sur} means `above', which relates to the fact that the function's codomain is completely covered. Its definition can be written as follows: a function $f$ is said to be surjective if
        \begin{equation}
            f: X \rightarrow Y: \forall y \in Y: \exists x \in X: f(x) = y \thinspace .
        \end{equation}

        A function is called injective (or: one-to-one) if no element of its codomain is mapped to twice. Mathematically, we would write: $f$ is an injective function if
        \begin{equation}
            f: X \rightarrow Y: \forall a, b \in X: f(a) = f(b) \Rightarrow a = b \thinspace .
        \end{equation}

        A function is called bijective (or: one-to-one and onto, a one-to-one correspondence), if it is both injective and surjective: every element of the codomain is mapped to by exactly one element of the domain. \\

        The identity function on a set $S$ is the function:
        \begin{equation}
            \id_S: S \rightarrow S: \id_S(s) = s \thinspace .
        \end{equation}

        \begin{figure}[H] \centering
            \includegraphics{images/sur_in_bi}
            \caption{A visual scheme of the terms surjective, injective and bijective.}
            \label{fig:sur_in_bi}
        \end{figure}

        Given Figure \ref{fig:sur_in_bi}, we can already see examples of surjective and injective functions. In Figure \ref{fig:function_color}, we can see an example of a function that is not surjective (not every color is mapped to), nor injective (the color red is mapped to twice). \\

    \subsection{Algebraic structures}
        Algebraic structures are a combination of a set, together with one or more operations, satisfying a list of axioms.

        \subsubsection{The mathematical definition of a group} \label{sec:group_def}
            A group has a mathematical definition. It is a set $G$\footnote{We often use the same symbol to denote the set of group elements and the actual group. I don't think there is anything wrong with this, as the distinction is most often clear from the context.} with elements $G=\set{g_1, g_2, \dots, g_n}$, together with an operation $\cdot$ (which is often called the group multiplication), meeting the following axioms:
            \begin{enumerate}
                \item closedness
                \begin{equation}
                    \forall g_1, g_2 \in G: g_1 \cdot g_2 \in G
                \end{equation}

                \item associativity
                \begin{equation}
                    \forall g_1, g_2, g_3 \in G: g_1 \cdot (g_2 \cdot g_3) = (g_1 \cdot g_2) \cdot g_3
                \end{equation}

                \item identity element
                \begin{equation} \label{eq:group_id}
                    \exists! \thinspace e \in G: \forall g \in G: e \cdot g = g \cdot e = g
                \end{equation}

                \item inverses
                \begin{equation}
                    \forall g \in G: \exists! \thinspace g^{-1} \in G: g \cdot g^{-1} = g^{-1} \cdot g = e
                \end{equation}
            \end{enumerate}
            If the axiom
            \begin{enumerate}
                \setcounter{enumi}{4}
                \item commutativity
                \begin{equation}
                    \forall g_1, g_2 \in G: g_1 \cdot g_2 = g_2 \cdot g_1
                \end{equation}
            \end{enumerate}
            is also met, the group is called Abelian. \\

        \subsubsection{Examples of groups}
            Since the definition of a group is so abstract, let us try to examine some examples of groups. \\

            As a first, let us consider a group that is familiar to all of us. Let us take the set $\mathbb{R}_0$: the rational numbers excluding $0$, together with the operation of multiplication. We can check that every group axiom holds (the identity element is $1$, and we know the inverse of every real number), even the commutative one. We can therefore say that $\mathbb{R}_0$ with multiplication is an Abelian group. \\

            In section \ref{sec:group_def}, we gave a general name to the group operation: group multiplication. This doesn't mean that the group operation can't be addition, for example, as `group multiplication' is just a name. A perfectly valid example of an Abelian group is the set of integers $\mathbb{Z}$, together with addition. Again, we can check that all group axioms hold (the identity element is $0$, and we all know the inverse of integers with respect to addition). \\

            As a slightly more complicated example of a group, we will consider the general linear group over $\mathbb{R}$ of degree $n$, denoted by $\GLg(n, \mathbb{R})$. This is the set of all invertible $n \times n$-matrices with real entries, with the operation of matrix multiplication. The identity element is $I_n$: the $n \times n$-identity matrix (a diagonal matrix with $1$ on the diagonal), and since we have specified the set as being the set of invertible matrices, every matrix has an inverse. We should emphasize that $\GLg(n, \mathbb{R})$ is not Abelian, as, in general, matrix multiplication is not commutative. A special case of this group is formed by requiring that the determinant of the invertible $n \times n$-matrices is equal to $1$. We call this set of matrices, together with matrix multiplication, the special linear group $\SLg(n)$. \\

            Many sets of matrices, together with the operation of multiplication form a group. We have for example $\Og(n)$, being the set of $n \times n$ orthogonal ($Q^\text{T} Q = Q Q^\text{T} = I_n$) matrices under matrix multiplication. A special group that is related to $\Og(n)$ is $\SOg(n)$, being the set of orthogonal matrices with determinant equal to $1$, under matrix multiplication. Furthermore, we also have the group $\Ug(n)$, being the set of $n \times n$ unitary matrices ($U U^\dagger = U^\dagger U = I_n$), under the group operation of matrix multiplication. Again, a special variant is $\SUg(n)$, being the set of $n \times n$ unitary matrices with determinant equal to $1$, under matrix multiplication. \\

            As a first more abstract example, let us take a look at the trivial group. It consists of the set $G = \set{e}$ under group multiplication. We have to specify that $e$ is the element for which equation (\ref{eq:group_id}) holds: $e$ is the identity element, and consequently its own inverse. With this in mind, we can check that the trivial group is Abelian. \\

            As another abstract example, let's take the set of elements
            \begin{equation}
                G = \set{E, C_2, \sigma_v, \sigma_v'} \thinspace ,
            \end{equation}
            with the multiplication table given in Table \ref{table:multiplication_table_C2v}.
            \begin{table}[H] \centering
                \begin{tabular}{r|rrrr}
                                & $E$           & $C_2$         & $\sigma_v$    & $\sigma_v'$   \\ \hline

                    $E$         & $E$           & $C_2$         & $\sigma_v$    & $\sigma_v'$   \\
                    $C_2$       & $C_2$         & $E$           & $\sigma_v'$   & $\sigma_v$    \\
                    $\sigma_v$  & $\sigma_v$    & $\sigma_v'$   & $E$           & $C_2$         \\
                    $\sigma_v'$ & $\sigma_v'$   & $\sigma_v$    & $C_2$         & $E$
                \end{tabular}
                \caption{An example multiplication table}
                \label{table:multiplication_table_C2v}
            \end{table}
            A multiplication table is read as follows. Take an element from the first column (for example $E$), and take an element of the second column ($C_2$), and find their product as $C_2 \cdot E = C_2$ (note that we read group multiplication conventionally from right to left). This set $G$, together with the multiplication $\cdot$ specified in the multiplication table, forms a group as all four group axioms are fulfilled. As commutativity is also fulfilled\footnote{An easy way to confirm the commutative property, is to verify that the multiplication table is symmetric with respect to its diagonal.}, this group is even Abelian. \\

            We can even introduce bigger sets:
            \begin{equation}
                G = \set{E, C_3, C^2_3, \sigma_v, \sigma_v', \sigma_v''} \thinspace ,
            \end{equation}
            \begin{table}[H] \centering
                \begin{tabular}{r|rrrrrr}
                                & $E$           & $C_3$         & $C^2_3$       & $\sigma_v$    & $\sigma_v'$   & $\sigma_v''$  \\ \hline

                    $E$         & $E$           & $C_3$         & $C^2_3$       & $\sigma_v$    & $\sigma_v'$   & $\sigma_v''$  \\
                    $C_3$       & $C_3$         & $C^2_3$       & $E$           & $\sigma_v'$   & $\sigma_v''$  & $\sigma_v$    \\
                    $C^2_3$     & $C^2_3$       & $E$           & $C_3$         & $\sigma_v''$  & $\sigma_v$    & $\sigma_v'$   \\
                    $\sigma_v$  & $\sigma_v$    & $\sigma_v''$  & $\sigma_v'$   & $E$           & $C^2_3$       & $C_3$         \\
                    $\sigma_v'$ & $\sigma_v'$   & $\sigma_v$    & $\sigma_v''$  & $C_3$         & $E$           & $C^2_3$       \\
                    $\sigma_v''$& $\sigma_v''$  & $\sigma_v'$   & $\sigma_v$    & $C^2_3$       & $C_3$         & $E$
                \end{tabular}
                \caption{Another example of a multiplication table}
                \label{table:multiplication_table_C3v}
            \end{table}
            Given the multiplication table in Table \ref{table:multiplication_table_C3v}, we can verify that the set $G$, together with the group multiplication forms a non-Abelian group. \\

        \subsubsection{The mathematical definition of a field}
            A field is a set $\F$ together with two binary operations $+$ and $\cdot$, which fulfills
            \begin{enumerate}
                \item $\F$, together with the operation $+$ is an Abelian group
                \item $\F\backslash\set{0_+}$\footnote{The set $\F$ without the identity element of the operation $+$.}, together with the operation $\cdot$ is an Abelian group,
                \item $\cdot$ is distributive with respect to $+$
            \end{enumerate}
            The last property, distributivity of $\cdot$ over $+$ means the following:
            \begin{align}
                \forall a, b, c \in \F: &a \cdot (b + c) = a \cdot b + a \cdot c \\
                & (a + b) \cdot c = a \cdot c + b \cdot c
            \end{align}

            Some important examples of fields include the field of the real numbers without $0$ ($\R_0$) together with multiplication and addition, and the field of the complex numbers without $0$ ($\C_0$) with the operations addition and multiplication. \\

        \subsubsection{The mathematical definition of a vector space}
            A vector space over a field $F$ is a set of vectors ($\vb{v} \in V$) together with two binary operations: the vector addition, $+$, and the scalar multiplication with an element of the field, $\cdot$, fulfilling the following axioms:
                \begin{enumerate}
                    \item $(V,+)$ is an Abelian group

                    \item $V$ is closed with respect to scalar multiplication
                    \begin{equation}
                        c \cdot \vb{v} \in V
                    \end{equation}

                    \item $V$ has an identity element for scalar multiplication
                    \begin{equation}
                        1 \in F: 1 \cdot \vb{v} = \vb{v}
                    \end{equation}

                    \item scalar multiplication is compatible with field multiplication
                    \begin{equation}
                        aÂ \cdot (b \cdot \vb{v}) = (ab) \cdot \vb{v}
                    \end{equation}

                    \item scalar multiplication is distributive over vector addition
                    \begin{equation}
                        a \cdot (\vb{u} + \vb{v}) = a \cdot \vb{u} + a \cdot \vb{v}
                    \end{equation}

                    \item scalar multiplication is distributive over field addition
                    \begin{equation}
                        (a + b) \cdot \vb{u} = a \cdot \vb{u} + b \cdot \vb{u}
                    \end{equation}
                \end{enumerate}

        \subsubsection{Examples of vector spaces}
            As I stumble upon examples, they will be included here.

    \subsection{Morphisms}
        A morphism is a map from one algebraic structure to another, preserving its structure.

        \subsubsection{Group homomorphisms and group isomorphisms - mathematical definitions}
            Say we have a group $G$ with elements $\set{a, b, \cdots}$ and group multiplication $\cdot$. Say we also have another group $G'$ with elements $\set{a', b', \cdots}$ and group multiplication $\cdot'$. A group homomorphism is a function
            \begin{equation}
               h: G \rightarrow G': g \mapsto g' = h(g)
            \end{equation}
            such that
            \begin{equation}
               \forall a, b \in G: h(a \cdot b) = h(a) \cdot' h(b) \thinspace .
            \end{equation}
            From this definition we can show that the identity $e$ of $G$ is mapped onto the identity $e'$ of $G'$ and that
            \begin{equation}
               \forall a \in G: h(a^{-1}) = h(a)^{-1}
            \end{equation}
            such that we can say that the function $h$ (the relation between the two groups) is compatible with the group structure. The proofs are given in appendix \ref{app:proof_hom_id} and \ref{app:proof_hom_inv} respectively. \\

            Equivalently, we can write for a group homomorphism $h$:
            \begin{align}
                h: G \rightarrow G': &\forall a, b, c \in G: \\
                &a \cdot b = c \Rightarrow h(a) \cdot' h(b) = h(c) \thinspace .
            \end{align}

            A special type of group homomorphism is a group endomorphism. This is a group homomorphism from a set $G$ to itself:
            \begin{equation}
                h: G \rightarrow G
            \end{equation}

            Another special group homomorphism is a group isomorphism. It is a group homomorphism that is bijective. \\

        \subsubsection{Examples of group homomorphisms and group isomorphisms}
            As I stumble upon examples, they will be included here.

        \subsubsection{Linear operators - mathematical definition}
            A linear map $M$ is a function (= mapping) between two vector spaces $V$ and $W$:
            \begin{equation}
                M: V \rightarrow W \thinspace ,
            \end{equation}
            such that $\forall \vb{u}, \vb{v} \in V; \forall a \in \F:$
            \begin{align}
                &M(\vb{u} + \vb{v}) = M(\vb{u}) + M(\vb{v})     && \text{$M$ `preserves' vector addition} \\
                &M(a \vb{u}) = a M(\vb{u})                      && \text{$M$ `preserves' scalar multiplication}
            \end{align}
            From this definition, we can see that a linear operator can be called a vector space homomorphism. \\

            Extending the concept of a linear map, we can introduce the term linear operator. A linear operator is a linear map $T$ from a vector space $V$ to itself, i.e. an endomorphism of $V$:
            \begin{equation}
                T: V \rightarrow V \thinspace .
            \end{equation}
            An automorphism is an invertible linear map from $V$ to itself. We can show that the set $\Aut(V)$, being the set of invertible linear operators of the vector space $V$ forms a group under the group operation operator multiplication.

        \subsubsection{Examples of isomorphisms}
            Let us consider a subset $C$ of the matrices with real entries ($x, y \in \R$), consisting of matrices of the form
            \begin{equation}
                \begin{pmatrix} x & y \\ -y & x \end{pmatrix}
            \end{equation}
            Then, defining $f$ as the field isomorphism $f: C \rightarrow \C$;
            \begin{equation}
                \begin{pmatrix} x & y \\ -y & x \end{pmatrix} \mapsto x + yi \thinspace ,
            \end{equation}
            it can be seen that the field $(C, +, \cdot)$ is isomorphic to the field $(\C, +, \cdot)$. \\

            We have seen that $\text{Aut}(V)$ is the automorphism group of $V$. By introducing a basis in $V$, we can represent these invertible linear operators as invertible linear matrices and we can say that $\Aut(V)$ is isomorphic (one-to-one correspondence) to $\GLg(n)$. \\

   \subsection{The mathematical definition of a representation}
        The mathematical branch that connects groups and vector spaces is called representation theory. A representation of a finite group $G$ on a finite-dimensional vector space $V$ is a homomorphism
        \begin{equation}
           \rho: G \rightarrow \text{GL}(V): g \mapsto \rho(g)
        \end{equation}
        of the group $G$ to the general linear group $\text{GL}(V)$, such that every group element $g$ is associated to an element of the general linear group. In other words, we associate every group element $g$ with an $n \times n$-matrix $\rho(g)$. The term homomorphism means that group structure is preserved:
        \begin{equation}
          \forall g_1, g_2 \in G: \rho(g_1 \cdot g_2) = \rho(g_1) \rho(g_2) \thinspace ,
        \end{equation}
        which means that the matrix representation $\rho(g_1 \cdot g_2)$ of the group multiplication of two group elements $g_1$ and $g_2$ is the matrix product of their respective matrix representations $\rho(g_1)$ and $\rho(g_2)$.
