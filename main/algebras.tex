\section{Algebras}
    Now that we have defined a bilinear operation, we can continue by adding another, more advanced, algebraic structure called an algebra.

    \subsection{The mathematical definition of an algebra}
        If we have a vector space $V$ over a field $\F$, we already have two operations available: vector addition and scalar multiplication. The natural way to extend this concept, is to define a map that combines two vectors into another vector. That is exactly how we end up with an algebra. If now add a bilinear operator $\star$ to a vector space $V$ over $\F$, then we will call $V$ an algebra (with $\star$) over $V$. Again, there is an unfortunate notation in which both $V$ represents the algebra, as well as the \\

        In some sense we could say that algebras are a generalization of fields in the way that field multiplication is now generalized to the bilinear operation of the algebra. In a sense, we can call the field multiplication a bilinear operation (in which the vector space associated to the bilinear operation is the field over itself). \\

        Let $\set{\vb{e}_i ; i=1,\dots,n}$ be a basis for the underlying $n$-dimensional vector space $V$ of the algebra. It is then possible, in much the same way as operators can be represented as matrices in a certain basis, to characterize the the multiplication $\star$ of the algebra as
        \begin{equation}
            \vb{e}_i \star \vb{e}_j = \sum_k^n f_{ijk} \vb{e}_k \thinspace ,
        \end{equation}
        in which $f_{ijk}$ are called the structure constants of the algebra. \\

        If $\star$ is associative, i.e.
        \begin{equation}
            \forall \vb{u}, \vb{v}, \vb{w}: \vb{u} \star (\vb{v} \star \vb{w}) = (\vb{u} \star \vb{v}) \star \vb{w} \thinspace ,
        \end{equation}
        then the algebra is called associative.

    \subsection{Examples of algebras}
        We all know examples of algebras, with the easiest example being the $(n \times n)$-matrices with matrix multiplication. \\

    \subsection{The mathematical definition of a Lie algebra}
        A Lie algebra is an algebra $\glie$ over the field $\F$, in which the bilinear operation is the Lie bracket. The Lie bracket $\comm{\cdot}{\cdot}$ is a bilinear function that further obeys
        \begin{enumerate}
            \item alternativity
            \begin{equation}
                \forall T_a \in \glie: \comm{T_a}{T_a} = 0
            \end{equation}

            \item the Jacobi identity
            \begin{equation}
                \forall T_a, T_b, T_c \in \glie: \comm{T_a}{\comm{T_b}{T_c}} + \comm{T_c}{\comm{T_a}{T_b}} + \comm{T_b}{\comm{T_c}{T_a}} = 0
            \end{equation}
        \end{enumerate}

        It can be shown that bilinearity and alternativity together imply anticommutativity:
        \begin{equation}
            \forall T_a, T_b \in \glie: \comm{T_b}{T_a} = - \comm{T_a}{T_b} \thinspace .
        \end{equation}

        In the physics community, the elements $T_a, T_b, \cdots$ are called the generators of the algebra if they are a basis for the underlying vector field. \\

        For the structure constants, the Jacobi identity implies
        \begin{equation}
            \sum_d^n (f_{bcd} f_{ade} + f_{abd} f_{cde} + f_{cad} f_{bde}) = 0 \thinspace .
        \end{equation}

        It is interesting to note that every associative algebra $A$ over a field $\F$ admits a Lie algebra $L(A)$ over the same field $\F$ (both having the same underlying vector space $V$), by defining the Lie bracket as the commutator:
        \begin{equation}
            \comm{T_a}{T_b} = T_a T_b - T_b T_a \thinspace .
        \end{equation}
        The associative algebra $A$ is then called the enveloping algebra of the Lie algebra $L(A)$.

    \subsection{Examples of Lie algebras}
        The most important examples of Lie algebras are those that are associated to a matrix Lie group. We have
        \begin{itemize}
            \item $\gllie(n, \R)$: the Lie algebra of the $(n \times n)$-matrices with real entries,
            \item $\sllie(n, \R)$: the Lie algebra of the $(n \times n)$-matrices with real entries and trace 0,
            \item $\olie(n) = \solie(n)$: the Lie algebra of the $(n \times n)$ skew-symmetric matrices with real entries,
            \item $\ulie(n) = \sulie(n)$: the Lie algebra of the $(n \times n)$ anti-Hermitian matrices.
        \end{itemize}

        The relation between the matrix Lie groups $G$ and their associated Lie algebras $\glie$ is
        \begin{equation}
            \glie = \set{M \in \F^{n \times n}; \forall t \in \R: \exp(t M) \in G} \thinspace .
        \end{equation}

    \subsection{The Lie algebra $\sulie(2)$}
        If we have a vector space of operators spanned by $\glie = \set{T^x, T^y, T^z}$ with the commutation relations
        \begin{align}
            & \comm{T^x}{T^y} = i T^z \\
            & \comm{T^y}{T^z} = i T^x \\
            & \comm{T^z}{T^x} = i T^y \thinspace ,
        \end{align}
        the algebra $\glie$ is said to be $\sulie(2)$. Another basis for $\sulie(2)$ could be given by
        \begin{align}
            & T^+ = T^x + i T^y \\
            & T^- = T^x - i T^y \\
            & T^z = T^z \thinspace ,
        \end{align}
        or, reversely
        \begin{align}
            & T^x = \frac{1}{2} \qty(T^+ + T^-) \\
            & T^y = \frac{1}{2i} \qty(T^+ - T^-) \\
            & T^z = T^z \thinspace ,
        \end{align}
        with the commutators
        \begin{align}
            & \comm{T^+}{T^-} = 2 T^z \\
            & \comm{T^z}{T^\pm} = \pm T^\pm \thinspace ,
        \end{align}
        and $T^+$ being the Hermitian adjoint of $T^-$
        \begin{equation}
            T^- = \qty(T^+)^\dagger \thinspace ,
        \end{equation}
        and $T^z$ being Hermitian:
        \begin{equation}
            \qty(T^z)^\dagger = T^z \thinspace .
        \end{equation}
        The (quadratic) Casimir invariant of $\sulie(2)$ is given by
        \begin{align}
            T^2 &= \qty(T^x)^2 + \qty(T^y)^2 + \qty(T^z)^2 \\
            &= T^+ T^- - T^z + \qty(T^z)^2 \thinspace ,
        \end{align}
        and it commutes with every generator:
        \begin{align}
            & \comm{T^2}{T^x} = \comm{T^2}{T^y} = \comm{T^2}{T^z} = 0 \\
            & \comm{T^2}{T^+} = \comm{T^2}{T^-} = \comm{T^2}{T^z} = 0 \thinspace .
        \end{align}

    \subsection{The generalized Gaudin algebra}
        Let us take a vector space spanned by $\set{S^x_u, S^y_u, S^z_u}$, where $S^\kappa_u \equiv S^\kappa(u)$ and $u \in \C$. The generalized Gaudin algebra is characterized by the commutation relations ($u \neq v$)
        \begin{align}
            & \comm{S^\kappa_u}{S^\kappa_v} = 0 \label{eq:gga_commutators_first} \\
            & \comm{S^x_u}{S^y_v} = i \qty( Y_{uv} S^z_u - X_{uv} S^z_v ) \\
            & \comm{S^y_u}{S^z_v} = i \qty( Z_{uv} S^x_u - Y_{uv} S^x_v ) \\
            & \comm{S^z_u}{S^x_v} = i \qty( X_{uv} S^y_u - Z_{uv} S^y_v ) \label{eq:gga_commutators_last} \thinspace ,
        \end{align}
        in which $\kappa=x,y,z$, $X_{uv} \equiv X(u,v)$, $Y_{uv} \equiv Y(u,v)$ and $Z_{uv} \equiv Z(u,v)$ are antisymmetric, i.e.
        \begin{equation}
            X(v, u) = - X(u, v)
        \end{equation}
        Furthermore, for the commutation relations (\ref{eq:gga_commutators_first}) to (\ref{eq:gga_commutators_last}) to be consistent with the Jacobi identity $\comm{S^x_u}{\comm{S^x_v}{S^y_w}}$, the Yang-Baxter equation
        \begin{equation}
            X(u, v) Y(v, w) + Y(w, u) Z(u, v) + Z(v, w) X(w, u) = 0
        \end{equation}
        has to hold. Gaudin \cite{gaudin1976} found solutions to this equation, and we will focus on the so-called $XXX$-case, in which
        \begin{equation}
            X(u, v) = Y(u, v) = Z(u, v) = \frac{1}{u - v} \thinspace ,
        \end{equation}
        such that the $XXX$-Gaudin algebra reduces to ($u \neq v$)
        \begin{align}
            & \comm{S^\kappa_u}{S^\kappa_v} = 0 \\
            & \comm{S^x_u}{S^y_v} = \frac{i}{u-v} \qty(S^z_u - S^z_v) \\
            & \comm{S^y_u}{S^z_v} = \frac{i}{u-v} \qty(S^x_u - S^x_v) \\
            & \comm{S^z_u}{S^x_v} = \frac{i}{u-v} \qty(S^y_u - S^y_v) \thinspace ,
        \end{align}
        In this case, it is a good idea to work in the basis
        \begin{align}
            & S^+_u = S^x_u + i S^y_u \\
            & S^-_u = S^x_u - i S^y_u \\
            & S^z_u = S^z_u \thinspace ,
        \end{align}
        with the commutators becoming ($u \neq v$)
        \begin{align}
            & \comm{S^+_u}{S^+_v} = \comm{S^-_u}{S^-_v} = \comm{S^z_u}{S^z_v} = 0 \label{eq:gaudin_commutators_pp} \\
            & \comm{S^+_u}{S^-_v} = \frac{2}{u-v} \qty(S^z_u - S^z_v) \label{eq:gaudin_commutators_pm} \\
            & \comm{S^z_u}{S^\pm_v} = \frac{\pm}{u - v} \qty(S^\pm_u - S^\pm_v) \label{eq:gaudin_commutators_zpm} \thinspace .
        \end{align}

        So far, the form of the generators of the Gaudin algebra has not been specified. To make a specification, we will use $N$ copies of an $\sulie(2)$-algebra, each carrying a real number $\varepsilon_i$ and we will choose in particular
        \begin{align}
            & S^+_u = \sum_i^N \frac{T^+_i}{u - \varepsilon_i} \\
            & S^-_u = \sum_i^N \frac{T^-_i}{u - \varepsilon_i} \\
            & S^z_u = \frac{1}{g} - \sum_i^N \frac{T^z_i}{u - \varepsilon_i} \thinspace ,
        \end{align}
        in which $g$ is a real number. Using the $\sulie(2)$-based realization of the Gaudin algebra, we can indeed show that the commutator relations (\ref{eq:gaudin_commutators_pp}) to (\ref{eq:gaudin_commutators_zpm}) hold. Let us also calculate $S^2_u$:
        \begin{equation}
            S^2_u = \frac{1}{g^2} - \frac{2}{g} \sum_i^N \frac{T^z_i}{u - \varepsilon_i} + \frac{1}{2} \sum_{ij}^N \frac{T^+_i T^-_j + T^-_i T^+_j + 2 T^z_i T^z_j}{(u - \varepsilon_i)(u - \varepsilon_j)} \thinspace .
        \end{equation}
        This operator has poles at every $\varepsilon_i$, so let's calculate the residues $R_i$. Furthermore, we will calculate a linear combination of the residues $\sum_i^N \varepsilon_i R_i$, leading to the $\sulie(2)$-Hamiltonian \cite{johnsonphd}
        \begin{equation}
            H_{\sulie(2)} = \sum_i^N \varepsilon_i T^z_i - g \sum_{ij}^N T^+_i T^-_j \thinspace .
        \end{equation}
